from tfinterface.model_base import ModelBase
from tfinterface.utils import select_columns, soft_if
from .experience_buffer import ExperienceReplay
from rl.policy import EpsGreedyQPolicy, GreedyQPolicy

import numpy as np
from numpy.random import choice
import random
import tensorflow as tf
from scipy.interpolate import interp1d

class DQN(ModelBase):

    def define_model(self, inputs, model, target_model, nb_actions, memory, policy=None, test_policy=None, enable_double_dqn=True, enable_dueling_network=False,
        dueling_type='avg', gamma=.99, batch_size=32, nb_steps_warmup=1000,
        train_interval=1, memory_interval=1, target_model_update=10000,
        delta_range=None, delta_clip=np.inf, scope="dqn", optimizer=tf.train.AdamOptimizer):

        self.memory = memory
        self.model = model
        self.target_model = target_model
        self.inputs = inputs
        self.policy = policy if policy else EpsGreedyQPolicy()
        self.test_policy = test_policy if test_policy else GreedyQPolicy()
        self.gamma = gamma
        self.nb_steps_warmup = nb_steps_warmup
        self.train_interval = train_interval
        self.memory_interval = memory_interval
        self.target_model_update = target_model_update
        self.delta_range = delta_range
        self.delta_clip = delta_clip


        with self.graph.as_default(), tf.variable_scope(scope):

            self.model_target = self.inputs.r + tf.reduce_max(self.target_model.Qs, axis=1) * self.inputs.done
            self.mode_error = self.model_target - self.model.Qsa
            self.model_loss = self.mode_error |> tf.nn.l2_loss |> tf.reduce_mean
            self.model_update = optimizer(self.inputs.learning_rate).minimize(self.model_loss, var_list=self.model.variables)

            if target_model_update < 1:
                self.update_target = tf.group(*[
                    tv.assign_add( target_model_update * (mv - tv) ) for mv, tm in zip(self.target_model.variables, self.model.variables)
                ])
            else:
                self.update_target = tf.group(*[
                    tv.assign( mv ) for mv, tm in zip(self.target_model.variables, self.model.variables)
                ])

            
